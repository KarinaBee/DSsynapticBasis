{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import packages.'''\n",
    "\n",
    "## If running for the first time, may need to install packages via terminal.\n",
    "## If importing errors, check package location and Python kernel match. If not, packages may need to be installed at location of Python kernel.\n",
    "\n",
    "# Data manipulation.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphing.\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File access.\n",
    "import json\n",
    "import openpyxl\n",
    "\n",
    "# Statistics.\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Key analysis variables.'''\n",
    "\n",
    "## THIS PANEL MUST BE UPDATED FOR ANALYSIS ##\n",
    "\n",
    "# Set the threshold value for selecting valid frames. Invalid frames are defined as frames with less than 3 pupil markers with a likelihood value above the threshold.\n",
    "pThreshold = 0.75\n",
    "\n",
    "# Videos dimensions are 640 x 516 pixels.\n",
    "fps = 100 # This is rig/camera-dependent.\n",
    "\n",
    "# Set the saccade threshold. Frames where the eye velocity/displacement is greater than the threshold are considered saccadic.\n",
    "saccade_threshold = 30/fps # Units are degrees per frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set up file paths.'''\n",
    "\n",
    "## THIS PANEL MUST BE UPDATED FOR ANALYSIS ##\n",
    "\n",
    "# Deeplabcut csv file paths; this script is written to take information from two cameras.\n",
    "dpl1 = '/Users/eugeneliang/Downloads/OKR/OriginalWildTypeAnimals/C57_male_b3.20.24_headpost7.2.24/10/2025-01-16_10-45-17_1DLC_Resnet50_OKR_FellerOct9shuffle4_snapshot_110.csv'\n",
    "dpl2 = '/Users/eugeneliang/Downloads/OKR/OriginalWildTypeAnimals/C57_male_b3.20.24_headpost7.2.24/10/2025-01-16_10-45-17_2DLC_Resnet50_OKR_FellerOct9shuffle4_snapshot_110.csv'\n",
    "\n",
    "# Visual stimulus json file path.\n",
    "dplJson = '/Users/eugeneliang/Downloads/OKR/OriginalWildTypeAnimals/C57_male_b3.20.24_headpost7.2.24/10/10.json'\n",
    "\n",
    "if dpl1 == dpl2:\n",
    "    raise Exception('DeepLabCut inputs are identical')\n",
    "\n",
    "# Identify the frame at which stim appears; needs to be externally determined; if determined from Fiji/ImageJ, subtract by 1. See Instructions for explanation.\n",
    "# Visual stimulus json file records stimulus timing relative to executing the stimulus program; does not intrinsically adjust to when the cameras begin recording.\n",
    "stim_appears = 539\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define useful functions.'''\n",
    "\n",
    "# Calculate distance between two coordinate points.\n",
    "def distance(x0, y0, x1, y1):\n",
    "    return np.sqrt((x1-x0)**2 + (y1-y0)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read in DeepLabCut data for IR cameras 1 and 2 as pandas dataframes.'''\n",
    "\n",
    "## This Jupyter notebook operates under the assumption that IR camera 1 and IR camera 2 have symmetric data (same number of columns and rows/frames).\n",
    "\n",
    "ir1_dpl = pd.read_csv(dpl1) # Dataframe with Deeplabcut (dpl) data for IR camera 1 (ir1).\n",
    "ir2_dpl = pd.read_csv(dpl2) # Dataframe with Deeplabcut (dpl) data for IR camera 2 (ir2).\n",
    "\n",
    "# Exchange auto-generated column labels for numeric headers.\n",
    "for df in [ir1_dpl, ir2_dpl]:\n",
    "    df.columns = [i for i in range(len(df.columns))] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Partition marker likelihood from DeepLabCut data.'''\n",
    "\n",
    "# Initialize empty dictionary for DeepLabCut likelihood values.\n",
    "dplLikelihood = {}\n",
    "\n",
    "# Generate DeepLabCut likelihood dataframe by selecting every third column from original DeepLabCut data; keys represent the two infrared cameras.\n",
    "dplLikelihood['ir1'] = pd.DataFrame(data=ir1_dpl[ir1_dpl.columns[::3]].iloc[2:, 1:], dtype=float)\n",
    "dplLikelihood['ir2'] = pd.DataFrame(data=ir2_dpl[ir2_dpl.columns[::3]].iloc[2:, 1:], dtype=float)\n",
    "\n",
    "# Clean up likelihood dataframes for further analysis.\n",
    "for key in dplLikelihood:\n",
    "    dplLikelihood[key].columns = ir1_dpl.iloc[0].unique()[1:] # Set likelihood dataframe column labels to pupil marker names.\n",
    "    dplLikelihood[key].reset_index(inplace=True)\n",
    "    dplLikelihood[key].drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "# Initialize empty dictionaries for pupil and corneal likelihood values.\n",
    "pupilLikelihood = {}\n",
    "cornealLikelihood = {}\n",
    "\n",
    "# Populate dictionary with pupil and corneal likelihood dataframes for each infrared cameras. Keys are 'ir1' and 'ir2'.\n",
    "for key in dplLikelihood:\n",
    "    pupilLikelihood[key] = dplLikelihood[key].iloc[:, :8]\n",
    "    cornealLikelihood[key] = dplLikelihood[key].iloc[:, 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Partition marker locations from DeepLabCut data.'''\n",
    "\n",
    "# Initialize empty dictionary for Deeplabcut coordinates.\n",
    "dplMarkers = {}\n",
    "\n",
    "# Generate DeepLabCut coordinates datraframe by dropping every third column from DeepLabCut.\n",
    "dplMarkers['ir1'] = pd.DataFrame(data=ir1_dpl.drop(ir1_dpl.columns[::3], axis=1))\n",
    "dplMarkers['ir2'] = pd.DataFrame(data=ir2_dpl.drop(ir2_dpl.columns[::3], axis=1))\n",
    "\n",
    "# Clean up markers tables.\n",
    "for key in dplMarkers:\n",
    "    dplMarkers[key].columns = dplMarkers[key].iloc[0]\n",
    "    dplMarkers[key] = dplMarkers[key].iloc[2:].astype(float)\n",
    "    \n",
    "    dplMarkers[key].reset_index(inplace=True)\n",
    "    dplMarkers[key].drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "# Initialize empty dictionary for separate 1D pupil markers.\n",
    "dplMarkers1D = {}\n",
    "\n",
    "# Generate 1-D dataframes (separate x, y coordiantes) for pupil markers in IR camera 1 and camera 2.\n",
    "for key in dplMarkers:\n",
    "    dplMarkers1D['x' + str(key)[2]] = dplMarkers[key].iloc[:, range(0, len(dplMarkers['ir1'].columns), 2)]\n",
    "    dplMarkers1D['y' + str(key)[2]] = dplMarkers[key].iloc[:, range(1, len(dplMarkers['ir1'].columns), 2)]\n",
    "\n",
    "# Initialize empty dictionary for separate 1D pupil coordinates and corneal reflections.\n",
    "pupilMarkers = {}\n",
    "cornealMarkers = {}\n",
    "\n",
    "# Populate dictionary with pupil and corneal coordinates dataframes for each infrared cameras. Keys are 'ir1' and 'ir2'.\n",
    "for key in dplMarkers1D:\n",
    "    pupilMarkers[key] = dplMarkers1D[key].iloc[:, :8]\n",
    "    cornealMarkers[key] = dplMarkers1D[key].iloc[:, 8:]\n",
    "\n",
    "# Generate corneal origin dataframe by selecting unique horizontal coordinates and corresponding vertical coordinates.\n",
    "corneal_origin = pd.DataFrame(data=[cornealMarkers['x1']['CR1'], cornealMarkers['y1']['CR3'], cornealMarkers['x2']['CR2'], cornealMarkers['y2']['CR3']],\n",
    "                          index=['xO1', 'yO1', 'xO2', 'yO2']\n",
    "                          ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Identfiy the pupil center by approximating a circle bounded by the pupil markers via a least squares solution (Coope method).'''\n",
    "\n",
    "## This method uses the information from all 8 pupil markers and uses the likelihood values from DeepLabCut to determine whether a frame is valid.\n",
    "## Valid frames are defined as having at least 3 markers above the likelihood threshold (pThreshold), since 3 points are needed to uniquely define a circle.\n",
    "## The 'radial center' is still calculated for invalid frames, but the frame number and camera are recorded so that these frames can be adjusted for in later calculations.\n",
    "\n",
    "# Initialize empty radial center dataframe with column labels.\n",
    "pupil_rad = pd.DataFrame(columns = ['xC1', 'yC1', 'xC2', 'yC2'])\n",
    "\n",
    "# Intialize dictionaries for storing information about frames with an insufficient number of points to determine pupil center.\n",
    "invalidFrames = {'ir1': [], 'ir2': []}\n",
    "invalCount = {'ir1': 0, 'ir2': 0}\n",
    "\n",
    "# Calculate radial center for each frame and add to radial center dataframe.\n",
    "for i in range(len(corneal_origin)):\n",
    "\n",
    "    # Identify markers with a likelihood value above the threshold.\n",
    "    sig_markers = {}\n",
    "    for key in ['ir1', 'ir2']:\n",
    "        likelihood_i = pupilLikelihood[key].iloc[i]\n",
    "        sig_markers[key] = likelihood_i[likelihood_i>pThreshold].index\n",
    "        \n",
    "        # Check if the current frame has at least 3 markers with a likelihood value greater than the pThreshold.\n",
    "        if len(sig_markers[key]) < 3:\n",
    "            \n",
    "            # Record the index (frame number) and increment the count for invalid frames.\n",
    "            invalidFrames[key].append(i)\n",
    "            invalCount[key] += 1\n",
    "\n",
    "    \n",
    "    # Slice x, y pupil coordinates for IR camera 1, 2 in each frame as a numpy array.\n",
    "    vectors_i = {}\n",
    "    for key in pupilMarkers.keys():\n",
    "        vectors_i[key] = np.array(pupilMarkers[key].iloc[i][sig_markers['ir' + str(key)[1]]])\n",
    "\n",
    "    # Set up the linear system.\n",
    "    matrices_i = {}\n",
    "    for j in range(1,3):\n",
    "        matrices_i['A' + str(j)] = np.c_[vectors_i['x' + str(j)], vectors_i['y' + str(j)], np.ones(len(sig_markers['ir' + str(j)]))]\n",
    "        matrices_i['b' + str(j)] = (vectors_i['x' + str(j)] ** 2) + (vectors_i['y' + str(j)] ** 2)\n",
    "    \n",
    "    # Solve the linear system.\n",
    "    X1=np.linalg.pinv(matrices_i['A1'])@matrices_i['b1']\n",
    "    X2=np.linalg.pinv(matrices_i['A2'])@matrices_i['b2']\n",
    "    \n",
    "    # Add radial center coordinates in either camera for ith frame to radial center dataframe.\n",
    "    pupil_rad.loc[i] = [X1[0]/2, X1[1]/2, X2[0]/2, X2[1]/2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate camera scale factor and generate dataframe with pupil angular position in each frame.'''\n",
    "\n",
    "# Set pupil center data to desired dataframe.\n",
    "pupil_center = pupil_rad\n",
    "\n",
    "# Generate dataframe where pupil center coordinates are relative to corneal origin; units are in pixels.\n",
    "pupil_ang = pupil_center - corneal_origin.values\n",
    "pupil_ang[pupil_ang.columns[1::2]] = -pupil_ang[pupil_ang.columns[1::2]] # Vertical axis is generated inverted; flip so +x/+y is right/upwards.\n",
    "\n",
    "# Calculate distance between centers of pupils for each frame in each IR camera.\n",
    "crocam = np.mean([distance(pupil_ang.loc[i, 'xC1'], pupil_ang.loc[i, 'yC1'], pupil_ang.loc[i, 'xC2'], pupil_ang.loc[i, 'yC2']) for i in range(len(corneal_origin))])\n",
    "\n",
    "# Calculate scale factor; units are degrees per pixel.\n",
    "scale = 12 / crocam\n",
    "\n",
    "# Adjust pupil center position by scale factor; units are in degrees.\n",
    "pupil_ang *= scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         xC1        yC1       xC2        yC2\n",
       " 0  12.832765  17.099171  5.826606  17.214605\n",
       " 1  12.555178  16.830420  5.771046  17.304988\n",
       " 2  12.541601  16.763466  5.825064  17.414407\n",
       " 3  12.621899  17.168715  5.860008  17.633862\n",
       " 4  12.493570  17.150491  5.732553  17.603420,\n",
       " np.float64(0.37069326171935013),\n",
       " {'ir1': 52, 'ir2': 371})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Preview pupil angular position dataframe and scale factor.'''\n",
    "\n",
    "None\n",
    "\n",
    "# View first five rows of pupil angular position dataframe, the calculated scale factor, and the count of invalid frames in either camera.\n",
    "pupil_ang.head(), scale, invalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Partition experimental json file and extract key visual stimulus information.'''\n",
    "\n",
    "## For orientations: 0 degrees is nasal/right, 90 is superior/up, 180 is temporal/left, 270 is inferior/down.\n",
    "\n",
    "# Store json file.\n",
    "exp_data = json.load(open(dplJson))\n",
    "exp_stim = exp_data['loggedStimuli'][0]\n",
    "\n",
    "# Store characteristic variables.\n",
    "stim_name = exp_stim['protocolName']\n",
    "stim_sf = exp_stim['spatialFrequency']\n",
    "\n",
    "# Store key timing variables.\n",
    "start_offset = exp_stim['_stimulusStartLog'][0]\n",
    "dirtime = exp_stim['_actualStimTime']\n",
    "\n",
    "# Define stimulus start frame.\n",
    "stim_start = (((((pd.Series(exp_stim['_stimulusStartLog'])) - start_offset) + exp_stim['_actualPreTime']) * fps) + stim_appears) // 1\n",
    "stim_end = (((((pd.Series(exp_stim['_stimulusEndLog'])) - start_offset) - exp_stim['_actualTailTime']) * fps) + stim_appears) // 1\n",
    "\n",
    "# Initialize empty dictionary for stimulus velocity in each orientation.\n",
    "stim_vel = {}\n",
    "\n",
    "# Our dome had an asymmetric distortion that we needed to correct for empircally, which is represented by the hard coded factors.\n",
    "# Visual stimuli are assigned signs (+/-) according to Cartesian coordinates (i.e. up and right are +, down and left are -).\n",
    "for dir in [0, 180]:\n",
    "    stim_vel[dir] = exp_stim['speed']*1.090837954*np.cos(np.deg2rad(dir))\n",
    "for dir in [90,270]:\n",
    "    stim_vel[dir] = exp_stim['speed']*1.315847955*np.sin(np.deg2rad(dir))\n",
    "\n",
    "# # If analyzing data with no dome distortion, run the following lines instead:\n",
    "# for dir in [0, 180]:\n",
    "#     stim_vel[dir] = exp_stim['speed']*np.cos(np.deg2rad(dir))\n",
    "# for dir in [90,270]:\n",
    "#     stim_vel[dir] = exp_stim['speed']*np.sin(np.deg2rad(dir))\n",
    "\n",
    "# Generate visual stimulus dataframe, which details the visual stimulus orientation, start frame, and end frame.\n",
    "vis_stim = pd.DataFrame(data=[exp_stim['_orientationLog'], stim_start, stim_end], index=['orientation', 'start', 'end'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>5646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "orientation    90\n",
       "start        1146\n",
       "end          5646"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Preview visual stimulus timing.'''\n",
    "\n",
    "vis_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate slow pursuit displacement.'''\n",
    "\n",
    "# Parameterize key variables.\n",
    "camera = min(invalCount)\n",
    "sigma = 2\n",
    "\n",
    "# Select stimulus orientation, start frame, and stop frame from visual stimulus dataframe.\n",
    "stim_orient = vis_stim.loc['orientation', 0]\n",
    "stim_start = vis_stim.loc['start', 0]\n",
    "stim_end = vis_stim.loc['end', 0]\n",
    "\n",
    "# Initialize empty dictionary to hold eye position data.\n",
    "eye_positions = {}\n",
    "\n",
    "# Select 1D dataframes from during the visual stimuli.\n",
    "eye_positions['x'] = pupil_ang['xC' + camera[2]].iloc[stim_start:stim_end]\n",
    "eye_positions['y'] = pupil_ang['yC' + camera[2]].iloc[stim_start:stim_end]\n",
    "\n",
    "# Generate invalid frame filter from appropriate camera.\n",
    "invalidFilter = invalidFrames[camera][stim_start:stim_end]\n",
    "\n",
    "# Replace invalid frames with the last frame with known positoin.\n",
    "for key in eye_positions:\n",
    "    for frame in invalidFilter:\n",
    "        sub_frame = frame - 1\n",
    "\n",
    "        # Check if the current invalid frame is the first frame during the visual stimulus presentation.\n",
    "        if frame == start:\n",
    "            while sub_frame in invalidFrames[camera] and sub_frame != 0: # Soft check to find the last frame with known position.\n",
    "                sub_frame -= 1\n",
    "            eye_positions[key][frame] = pupil_ang[key + 'C' + camera[2]][sub_frame]\n",
    "        else:\n",
    "            eye_positions[key][frame] = eye_positions[key][sub_frame]\n",
    "\n",
    "# Apply a Gaussian filter to eye position data.\n",
    "for key in eye_positions:\n",
    "    eye_positions[key] = pd.Series(gaussian_filter1d(eye_positions[key].astype(float), sigma))\n",
    "\n",
    "# Initialize empty dictionary for eye displacement data.\n",
    "eye_displacements = {}\n",
    "\n",
    "# Calculate displacements; eye displacement dictionary inherits keys from eye position dictionary.\n",
    "for key in eye_positions:\n",
    "    eye_displacements[key] = np.insert(np.gradient(eye_positions[key], eye_positions[key].index), 0, 0)\n",
    "\n",
    "# Calculate total displacement of pupil in each frame and generate a mask for saccadic activity.\n",
    "total_displacement = np.sqrt((eye_displacements['x'] ** 2) + (eye_displacements['y'] ** 2))\n",
    "saccade_id = total_displacement > saccade_threshold\n",
    "\n",
    "# Count the number of non-continuous saccadic events and use the saccade mask to replace saccadic frames with 0 displacement in eye displacement dataframes.\n",
    "numSaccades = np.sum(np.diff(np.concatenate(([0], saccade_id))) == 1)\n",
    "\n",
    "for key in eye_displacements:\n",
    "    eye_displacements[key][saccade_id] = 0 \n",
    "\n",
    "# Integrate filtered displacement data to return positional data with no saccades.\n",
    "horz_noSaccade = pd.Series(np.cumsum(eye_displacements['x']))\n",
    "vert_noSaccade= pd.Series(np.cumsum(eye_displacements['y']))\n",
    "\n",
    "# Calculate gain values.\n",
    "gain_x = (horz_noSaccade.iloc[-1])/(stim_vel[stim_orient]*dirtime)\n",
    "gain_y = (vert_noSaccade.iloc[-1])/(stim_vel[stim_orient]*dirtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5249627914340943), np.float64(0.3265035536809035), np.int64(51))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''View x gain, y gain, and the number of saccadic events for current replicate.'''\n",
    "\n",
    "gain_x, gain_y, numSaccades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Export pupil angular position dataframe to excel sheet.'''\n",
    "\n",
    "None\n",
    "\n",
    "## Uncomment and run the  following lines when above data is finalized. To un-comment rows, highlight desired rows and enter (Cntl + /) or (Cmd + /).\n",
    "\n",
    "# # Export pupil angular position dataframe to excel sheet in local Downloads folder.\n",
    "# pupil_ang.to_excel('pupil_ang_test.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
